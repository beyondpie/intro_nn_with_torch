import random
import pandas as pd
import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torch.autograd import Variable
from torch.utils.data import DataLoader,TensorDataset

from sklearn.model_selection import train_test_split

import os
os.environ['KMP_DUPLICATE_LIB_OK']= 'True'

class Net_1(nn.Module):
    def __init__(self, n_intput, neural_num, d_prob=0.5):
        super(Net_1, self).__init__()
        self.linears = nn.Sequential(
            nn.Linear(n_intput, neural_num),
            nn.ReLU(inplace=True),

            nn.Dropout(d_prob),
            nn.Linear(neural_num, neural_num),
            nn.ReLU(inplace=True),

            nn.Dropout(d_prob),
            nn.Linear(neural_num, neural_num),
            nn.ReLU(inplace=True),

            nn.Dropout(d_prob),
            nn.Linear(neural_num, 1),
        )

    def forward(self, x):
        return self.linears(x)
    
    
class Net_2(nn.Module):
    def __init__(self,n_input,n_hidden,n_output):
        super(Net_2,self).__init__()
        self.hidden1 = nn.Linear(n_input,n_hidden)
        self.hidden2 = nn.Linear(n_hidden,n_hidden)
        self.predict = nn.Linear(n_hidden,n_output)
        self.dropout = nn.Dropout(0.5)
        
    def forward(self,input):
        out = self.hidden1(input)
        out = F.relu(out, inplace=True)
        
        out = self.dropout(out)
        out = self.hidden2(out)
        out = F.relu(out, inplace=True)

        out = self.dropout(out)
        out = self.hidden2(out)
        out = F.relu(out, inplace=True)

        out = self.dropout(out)
        out =self.predict(out)

        return out    


dfx = pd.DataFrame()
dfy = pd.DataFrame()

dfx['x'] = pd.Series(np.random.rand(1000)).astype(np.float32)
dfx['y'] = pd.Series(np.random.uniform(40,80,1000)).astype(np.float32)

dfy['z'] = dfx.apply(lambda x: pow(x['x'],2) + 3*x['y'] + random.random(), axis=1).astype(np.float32)

dfx = torch.tensor(dfx.astype(np.float32).values)
dfy = torch.tensor(dfy.astype(np.float32).values)

x_train, x_test, y_train, y_test = train_test_split(dfx, dfy, test_size = 0.15)

if len(y_train.shape) == 1:
    y_train = y_train.reshape(y_train.shape[0],1)
    
if len(y_test.shape) == 1:
    y_test = y_test.reshape(y_test.shape[0],1)    

train_set = TensorDataset(x_train, y_train)
test_set = TensorDataset(x_test, y_test)
#定义迭代器
train_data = DataLoader(dataset = train_set, batch_size = 64, shuffle=True)
test_data  = DataLoader(dataset = test_set, batch_size = 64, shuffle=False)

### Use Model 1 with sequential
net1 = Net_1(2,1024,1)
print(net1)

# optimizer = torch.optim.SGD(net.parameters(),lr = 0.0001)
optimizer = torch.optim.Adam(net1.parameters(), lr=0.0001)
loss_func = torch.nn.MSELoss()

for t in range(300):
    for tdata, tlabel in train_data:
        #前向传播
        prediction = net1(tdata)
        #记录单批次一次batch的loss
        loss = loss_func(prediction,tlabel)
        #反向传播
        optimizer.zero_grad()
        
        loss.backward()
        
        optimizer.step()
        
    if t%100 ==0:
        print('Loss = %.4f' % loss.data)

### Use Model 2 with sequential
net2 = Net_2(2,1024,1)
print(net2)

# optimizer = torch.optim.SGD(net.parameters(),lr = 0.0001)
optimizer = torch.optim.Adam(net2.parameters(), lr=0.0001)
loss_func = torch.nn.MSELoss()

for t in range(300):
    
    for tdata, tlabel in train_data:
        #前向传播
        prediction = net2(tdata)
        #记录单批次一次batch的loss
        loss = loss_func(prediction,tlabel)
        #反向传播
        optimizer.zero_grad()
        
        loss.backward()
        
        optimizer.step()
        
    if t%100 ==0:
        print('Loss = %.4f' % loss.data)
